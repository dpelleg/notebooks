{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import datetime\n",
    "import json\n",
    "import re\n",
    "import math\n",
    "import ims\n",
    "import utils\n",
    "\n",
    "# Analyse segment statistics and generate an HTML table for public consumption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/ridelogs/segments-20201124.json\n",
      "data/ridelogs/202012.json\n",
      "data/ridelogs/202011.json\n"
     ]
    }
   ],
   "source": [
    "# gather data\n",
    "md = utils.get_segment_metadata()\n",
    "rl_ = utils.get_ridelogs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add closest climate station \n",
    "\n",
    "#TODO: cache the result and store back in segments file\n",
    "from stations import closest_station\n",
    "\n",
    "def find_closest(x):\n",
    "    xl = list(map(float, x.strip('][').split(', ')))\n",
    "    return(closest_station(xl[0], xl[1]))\n",
    "\n",
    "#md_meta.drop(columns='closest', inplace=True)\n",
    "md['closest_ims'] = None\n",
    "# fill closest station \n",
    "md['closest_ims'] = md.apply(lambda r : find_closest(r['start_latlng']) if pd.isnull(r['closest_ims']) else r['closest'], axis=1)\n",
    "\n",
    "# save a table aside\n",
    "md_meta = md[['id', 'name', 'distance', 'region_name', 'region_url', 'closest_ims']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get historical average user per day, based on the number of days the segments exists, and the total effort counts\n",
    "# BUGBUG: Strava also counts efforts performed before the creation date\n",
    "c = 'created_at'\n",
    "md[c] = pd.to_datetime(md[c])\n",
    "c = 'time_retrieved'\n",
    "md[c] = pd.to_datetime(md[c], utc=True)\n",
    "md['hist_length'] = md['time_retrieved'] - md['created_at']\n",
    "md['hist_length_days'] = md['hist_length'].apply(lambda x: x.days)\n",
    "md['weekly_avg'] = 7*md['effort_count'] / md['hist_length_days']\n",
    "\n",
    "#md[['id', 'name', 'weekly_avg']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the distribution across days of the week\n",
    "\n",
    "tf = pd.read_csv('data/trailforks.csv')\n",
    "# fix string dates\n",
    "tf['date_orig'] = tf['date']\n",
    "tf['date'] = pd.to_datetime(tf['date'].apply(lambda s : re.sub('(.*[ap]m).*', '\\\\1', s)),\n",
    "                          format='%b %d, %Y @ %I:%M%p', errors='raise')\n",
    "\n",
    "tf['weekday'] = tf['date'].dt.weekday\n",
    "wdist = tf['weekday'].value_counts(normalize=True)\n",
    "wdist = pd.DataFrame(data = {'weekday_weight' : wdist, 'weekday' : wdist.index.values})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply weekly distribution to per-trail usage\n",
    "left = md\n",
    "right=wdist\n",
    "# cross join\n",
    "md = left.assign(key=1).merge(right.assign(key=1), on='key').drop('key', 1)\n",
    "md['daily_avg'] = md['weekly_avg'] * md['weekday_weight']\n",
    "#md['id'] = md['id'].map(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mdmd = md[['id', 'name', 'weekday', 'daily_avg']]\n",
    "#md_meta.query('id == \"17443790\"')\n",
    "#mdmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Tabulate ridelog data with date as index\n",
    "rl2 = pd.pivot_table(rl_, index='date', values='effort_count', columns='segment_id')\n",
    "rl2.set_index(pd.DatetimeIndex(rl2.index.values), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resample daily, interpolate missing values, and diff against the previous day\n",
    "daily = rl2.resample('1D').interpolate().fillna(method='bfill').diff()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the daily average in each segment\n",
    "\n",
    "# first, convert the table to long format\n",
    "all_segs = daily.columns\n",
    "d2 = daily.reset_index()\n",
    "d3 = d2.melt(id_vars = 'index', value_vars=all_segs)\n",
    "\n",
    "d4 = d3.rename(columns = {'index' : 'date'})\n",
    "d4['weekday'] = d4['date'].dt.weekday\n",
    "\n",
    "#print(d4.dtypes)\n",
    "#print(md.dtypes)\n",
    "# tack on the daily averages\n",
    "md_short = md[['id', 'weekday', 'daily_avg', 'closest_ims']]\n",
    "d5 = d4.merge(md_short, how='left', left_on=['segment_id', 'weekday'], right_on=['id','weekday'])\n",
    "\n",
    "# compute usage relative to the daily average\n",
    "d5['relative_usage'] = d5['value'] / d5['daily_avg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42##2020/12/01\n",
      "42##2020/11/30\n",
      "42##2020/12/06\n",
      "42##2020/12/05\n",
      "42##2020/11/26\n",
      "42##2020/11/25\n",
      "42##2020/11/27\n",
      "42##2020/11/26\n",
      "42##2020/11/28\n",
      "42##2020/11/27\n",
      "42##2020/11/29\n",
      "42##2020/11/28\n",
      "42##2020/11/30\n",
      "42##2020/11/29\n",
      "42##2020/12/02\n",
      "42##2020/12/01\n",
      "42##2020/12/03\n",
      "42##2020/12/02\n",
      "42##2020/12/04\n",
      "42##2020/12/03\n",
      "42##2020/12/05\n",
      "42##2020/12/04\n"
     ]
    }
   ],
   "source": [
    "rain_days = utils.get_rain_days(d5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "d6 = d5[['date', 'segment_id', 'relative_usage']].copy()\n",
    "\n",
    "# Add rain measurements\n",
    "segments_with_stations = d6.merge(md_meta, how='left', left_on='segment_id', right_on='id')\n",
    "segments_with_stations.drop(columns='id', inplace=True)\n",
    "segments_with_rainfall = segments_with_stations.merge(rain_days, how='left', left_on=['closest_ims', 'date'], right_on=['closest_ims', 'date'])\n",
    "\n",
    "d6 = segments_with_rainfall.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add rainfall weekly running sum\n",
    "d6.sort_values('date', inplace=True)\n",
    "d6['rain_7d'] = d6.groupby('segment_id')['rain_mm'].apply(lambda x : x.rolling(7).sum()).fillna(0)\n",
    "\n",
    "# Add soil moisture\n",
    "d6['soil_moisture'] = d6.groupby('segment_id')['rain_mm'].apply(utils.bathtub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trim to just most recent day\n",
    "lastdate = d6['date'].max()\n",
    "d7 = d6.query(\"date == @lastdate\").copy()\n",
    "\n",
    "# re-tabulate\n",
    "#d7 = pd.pivot_table(d6, index='date', values='relative_usage', columns='segment_id')\n",
    "\n",
    "#pd.to_datetime(d7.index.values).weekday\n",
    "ru = d7.loc[:, 'relative_usage'].copy()\n",
    "ru.clip(lower=0, upper=1, inplace=True)\n",
    "d7.loc[:, 'relative_usage'] = ru.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    from matplotlib.dates import DateFormatter\n",
    "    sns.lineplot(data=d8, dashes=False, marker='o')\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "\n",
    "    plt.gca().xaxis.set_major_formatter(DateFormatter(\"%m-%d\"))\n",
    "    plt.xticks(rotation=45)\n",
    "    None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare for display as nice HTML\n",
    "def link2(a, id):\n",
    "    return f'<a href=\"{a}\">{id}</a>'\n",
    "\n",
    "rideability_color = lambda x: '<div style=\"background-color: {}\">{}</div>'.format(('Chartreuse' if x>80 else 'DarkOrange' if x>30 else 'OrangeRed'), x)\n",
    "\n",
    "d8 = d7\n",
    "dfout = d8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#format the date\n",
    "dateout = lastdate.strftime('%d/%m/%Y')\n",
    "dfout.rename(columns = { 'relative_usage' : 'rideability'}, inplace=True)\n",
    "\n",
    "dfout['link'] = dfout.apply(lambda x: link2(f\"https://www.strava.com/segments/{x['segment_id']}\", x['name']), axis=1)\n",
    "dfout['region_link'] = dfout.apply(lambda x: link2(x['region_url'], x['region_name']), axis=1)\n",
    "dfout['distance'] = dfout['distance'].map(lambda x : \"%.0f\" % x)\n",
    "\n",
    "dfout.drop(columns=['date', 'segment_id', 'name'], inplace=True)\n",
    "dfout['rideability'] = dfout['rideability'].map(lambda x : math.floor(100*x))\n",
    "dfout['rain_mm'] = dfout['rain_mm'].map(lambda x : \"%.1f\" % x)\n",
    "dfout['rain_7d'] = dfout['rain_7d'].map(lambda x : \"%.0f\" % x)\n",
    "                                        \n",
    "# re-order columns\n",
    "dfout = dfout[['rideability', 'link', 'distance', 'region_link', 'rain_mm', 'rain_7d']].copy()\n",
    "\n",
    "dfout.rename(columns = {'rideability' : 'מדד רכיבות', 'link' : 'מקטע', 'distance' : 'אורך (מטר)', 'region_link' : 'איזור', 'rain_mm' : 'גשם יומי מ״מ', 'rain_7d' : 'גשם מצטבר שבועי מ״מ'},\n",
    "             inplace=True)\n",
    "\n",
    "htmlout = dfout.to_html(formatters={'מדד רכיבות': rideability_color},\n",
    "                        render_links=True, classes=\"table\",\n",
    "                        escape=False, index=False, border=1)\n",
    "\n",
    "\n",
    "# Add decorations and save to file\n",
    "\n",
    "title = 'מדד רכיבות'\n",
    "update_ts = '<br>' +  \"עדכון אחרון: {}\".format(dateout) + '</br>\\n'\n",
    "\n",
    "with open('preamble.txt') as f:\n",
    "    preamble = \" \".join([l.rstrip() for l in f]) \n",
    "\n",
    "with open('epilog.txt') as f:\n",
    "    epilog = \"\\n\".join([l.rstrip() for l in f]) \n",
    "\n",
    "html_preamble = '<html><head><meta charset=\"utf-8\"><meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\\n<link rel=\"stylesheet\" href=\"https://maxcdn.bootstrapcdn.com/bootstrap/3.4.1/css/bootstrap.min.css\">\\n<title>' + title + '</title>\\n</head><body dir=rtl>\\n' + preamble + \"\\n\" + update_ts + '<div class=\"container\">\\n'\n",
    "htmlout = html_preamble + htmlout + \"</div>\\n\" + epilog\n",
    "\n",
    "fileout = \"data/out/rides.html\"\n",
    "\n",
    "with open(fileout, \"w\", encoding=\"utf-8\") as file:\n",
    "    file.write(htmlout)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
