{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Model the usage of MTB trails as a function of weather conditions\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import spearmanr\n",
    "import utils\n",
    "import math\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "import numpy as np\n",
    "from datetime import date, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# gather data\n",
    "md = utils.get_segment_metadata()\n",
    "# ignore inactive segments\n",
    "md = md[md['active_modeling']]\n",
    "\n",
    "#md['closest_ims'] = md['closest_ims'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rl_ = utils.get_ridelogs()\n",
    "\n",
    "# Trim junk\n",
    "md = md[['id', 'name', 'closest_ims']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "d5 = rl_.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# add the closest IMS station\n",
    "d6 = d5.merge(md[['id', 'closest_ims', 'name']], how='right', left_on=['segment_id'], right_on=['id'])\n",
    "#md[['name','closest_ims']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "weather_days = utils.get_weather_days(d6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Add rain measurements\n",
    "data = d6.merge(weather_days, how='left', left_on=['closest_ims', 'date'], right_on=['closest_ims', 'date'])\n",
    "\n",
    "# cumulative measures of rainfall\n",
    "\n",
    "data.sort_values('date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# add lockdown value\n",
    "data['lockdown'] = 0\n",
    "data.loc[(data['date'] > '2021-01-07'), 'lockdown'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data['rain_7d'] = data.fillna(0).groupby('segment_id')['rain_mm'].apply(lambda x : x.rolling(7).sum().clip(lower=0))\n",
    "#data['soil_moisture'] = data.groupby('segment_id')['rain_mm'].apply(utils.bathtub)\n",
    "df_orig = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def bathtub_set(data_, soilmodel, **kwargs):\n",
    "    soil = np.array(soilmodel(data_[['rain_mm', 'wind_ms']], **kwargs)).reshape(-1, 1)\n",
    "    rain = (np.array(data_['rain_mm']) > 5).astype(int)    # indictor for: was there any rain on this particular day?\n",
    "    rain = rain.reshape(-1, 1)\n",
    "    lockdown = np.array(data_['lockdown']).reshape(-1, 1)\n",
    "    X = np.concatenate((soil, rain, lockdown), axis=1)\n",
    "    cmap = ['soil', 'rain', 'lockdown']\n",
    "    return (X, cmap)\n",
    "\n",
    "def regress(X, y):\n",
    "    # remove NaNs. We do this by stuffing everything into a dataframe first\n",
    "    dfXy = pd.DataFrame(X)\n",
    "    dfXy['y'] = y.values\n",
    "    dfXy.dropna(inplace=True)\n",
    "    # now unpack\n",
    "    Xy = np.array(dfXy.values)\n",
    "    X = Xy[:,:-1]\n",
    "    y = Xy[:, -1].reshape(-1, 1)\n",
    "\n",
    "    nrows = X.shape[0]\n",
    "    # skip if there's too little data\n",
    "    # skip if the moisture model didn't give us examples of dry soil (below 1)\n",
    "    if (nrows <= 2) or (X[:, 0].min() > 1):\n",
    "        return {'coef' : None, 'intercept' : None, 'score' : -1}\n",
    "    # We typically get many many examples with X=0 (dry soil), down-weigh them\n",
    "    Xsoil = X[:, 0].reshape(-1)\n",
    "    weights = np.ones(Xsoil.shape)\n",
    "    nzeros = np.count_nonzero(Xsoil == 0)\n",
    "    if nzeros > 0:\n",
    "        # we collapse all the zero points to have a total weight of one\n",
    "        weights[Xsoil == 0] = 1/nzeros\n",
    "    try:\n",
    "        reg = Ridge(alpha=1E-8, normalize=True).fit(X, y, sample_weight = weights)\n",
    "        #reg = LinearRegression(normalize=True).fit(X, y, sample_weight = weights)\n",
    "        coef = reg.coef_[0]\n",
    "        score = reg.score(X, y, sample_weight = weights)\n",
    "        # apply some sanity checks\n",
    "        # we need more soil moisture = less rides, not the opposite\n",
    "        if coef[0] > 0:\n",
    "            score = -1\n",
    "        # we need more rain today = less rides, not the opposite\n",
    "        if coef[1] > 0:\n",
    "            score = -1\n",
    "        # we need more lockdown today = less rides, not the opposite\n",
    "        if coef[2] > 0:\n",
    "            score = -1\n",
    "        return {'coef' : reg.coef_[0], 'intercept' : reg.intercept_[0], 'score' : score}\n",
    "    except ValueError:   # probably not enough data\n",
    "        return {'coef' : None, 'intercept' : None, 'score' : -1}\n",
    "\n",
    "def best_bathtub(data_):\n",
    "    mydata = data_.copy()\n",
    "    out = []\n",
    "\n",
    "    # Try the geometric model\n",
    "    clist = list(np.arange(4, 80, 4))\n",
    "    #clist = list(np.arange(4, 50, 8))\n",
    "\n",
    "    dlist = list(np.arange(0.5, 0.65, 0.05))\n",
    "    dlist.extend(np.arange(0.65, 0.8, 0.05))\n",
    "    dlist.extend(np.arange(0.8, 1, 0.05))\n",
    "\n",
    "    wlist = list(np.arange(0, 3, 0.25))\n",
    "    #wlist = [0, 1]\n",
    "    #wlist = []\n",
    "\n",
    "    for c in clist:\n",
    "        for d in dlist:\n",
    "            for w in wlist:\n",
    "                X, cmap = bathtub_set(mydata, utils.bathtub_geom_, capacity=c, drainage_factor=d, fwind=w)\n",
    "                p = regress(X, mydata['nrides'])\n",
    "                if p['score'] > -1:\n",
    "                    outdict = {'f': 'bathtub_geom', 'capacity': c, 'drainage_factor' : d, 'fwind' : w,\n",
    "                               'intercept' : p['intercept']}\n",
    "                    for ci in range(len(cmap)):\n",
    "                        outdict['c_' + cmap[ci]] = p['coef'][ci]\n",
    "                    out.append([p['score'], outdict])\n",
    "    \n",
    "    #Try the basic model\n",
    "    clist = list(np.arange(1, 10, 0.5))\n",
    "    clist.extend(range(10,80,4))\n",
    "    #clist = range(10, 30, 5)\n",
    "    \n",
    "    dlist = list(np.arange(5, 10, 0.5))\n",
    "    dlist.extend(range(10,25))\n",
    "    \n",
    "    wlist = list(np.arange(0, 3, 0.25))\n",
    "    #wlist = [0, 1]\n",
    "    \n",
    "    for c in clist:\n",
    "        for d in dlist:\n",
    "            for w in wlist:\n",
    "                # we want to ensure some margin between capacity and drainage\n",
    "                if c > d + 2:\n",
    "                    X, cmap = bathtub_set(mydata, utils.bathtub_, capacity=c, drainage=d, fwind=w)\n",
    "                    p = regress(X, mydata['nrides'])\n",
    "                    if p['score'] > -1:\n",
    "                        outdict = {'f': 'bathtub', 'capacity': c, 'drainage' : d, 'fwind' : w,\n",
    "                                             'intercept' : p['intercept']}\n",
    "                        for ci in range(len(cmap)):\n",
    "                            outdict['c_' + cmap[ci]] = p['coef'][ci]\n",
    "                        out.append([p['score'], outdict])\n",
    "\n",
    "    if(len(out) > 0):\n",
    "        cdf = pd.DataFrame(out, columns=['score', 'par'])\n",
    "        idxmax = cdf['score'].idxmax()\n",
    "        if(math.isnan(idxmax)):\n",
    "            idxmax = 0\n",
    "        return cdf.iloc[idxmax]\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = df_orig.copy()\n",
    "out = []\n",
    "seglist = df['segment_id'].unique()\n",
    "#seglist = ['17421855']\n",
    "for seg in seglist:\n",
    "    print(seg, end=\"...\")\n",
    "    mydata = df.query(\"segment_id == @seg\")\n",
    "    res = best_bathtub(mydata)\n",
    "    if res is not None:\n",
    "        res = res.to_dict()\n",
    "        res['segment_id'] = seg\n",
    "        out.append(res)\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = pd.DataFrame(out)\n",
    "# Compute the days to dry\n",
    "params['dtd'] = None\n",
    "\n",
    "exploded = pd.DataFrame.from_records(params['par'])\n",
    "params = pd.concat([params, exploded], axis='columns')\n",
    "\n",
    "# check we have all needed columns\n",
    "for c in ['drainage', 'drainage_factor']:\n",
    "    if c not in params.columns:\n",
    "        params[c] = None\n",
    "\n",
    "\n",
    "# We compute the moisture value which yields 0.9 of the intercept (soil is 90% dry)\n",
    "params['y90'] = 0.9*exploded['intercept']\n",
    "params['x90'] = (params['y90'] - exploded['intercept'])/exploded['c_soil']\n",
    "\n",
    "# compute for the additive model\n",
    "rows = (params['f'] == 'bathtub')\n",
    "params.loc[rows, 'dtd'] = (params['capacity'] - params['x90'])/params['drainage']\n",
    "\n",
    "# compute for the geometric model\n",
    "rows = (params['f'] == 'bathtub_geom')\n",
    "# how many times to multiply by the factor until we reach a value of x90?\n",
    "params.loc[rows, 'dtd'] = params[rows].apply(lambda r: (math.log(r['y90']) -math.log(r['capacity']))/math.log(r['drainage_factor']), axis=1)\n",
    "\n",
    "params = params.merge(md, how='left', left_on='segment_id', right_on='id').drop(columns='id')\n",
    "params[['segment_id', 'score', 'par']].to_csv('data/segments/params.csv', float_format='%.3g', index=False)\n",
    "\n",
    "params[['name', 'segment_id', 'dtd', 'score', 'closest_ims', 'capacity', 'drainage', 'drainage_factor', 'fwind', 'c_lockdown']].sort_values('dtd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 1, figsize=(8,8))\n",
    "sns.set_style('ticks')\n",
    "\n",
    "exploded = pd.DataFrame.from_records(params['par'])\n",
    "exploded['score'] = params['score']\n",
    "\n",
    "# plot for the additive model\n",
    "rows = (exploded['f'] == 'bathtub')\n",
    "if rows.sum() > 0:\n",
    "    sns.scatterplot(data=exploded[rows], x='capacity', y='drainage', size='score', hue='fwind', ax=ax[0])\n",
    "\n",
    "# plot for the geometric model\n",
    "rows = (exploded['f'] == 'bathtub_geom')\n",
    "if rows.sum() > 0:\n",
    "    sns.scatterplot(data=exploded[rows], x='capacity', y='drainage_factor', size='score', hue='fwind', ax=ax[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "names = df['segment_id'].unique()\n",
    "fig, ax = plt.subplots(figsize=(10,50), nrows=len(names), ncols=1)\n",
    "\n",
    "for vi in range(len(names)):\n",
    "    seg = names[vi]\n",
    "    mydata = df.query(\"segment_id == @seg\").copy()\n",
    "    p = params.query(\"segment_id == @seg\")\n",
    "    if len(p) > 0:\n",
    "        f = p.iloc[0].par['f']\n",
    "        name = mydata.iloc[0]['name']\n",
    "        score = p.iloc[0]['score']\n",
    "        capacity = p.iloc[0].par['capacity']\n",
    "        fwind = p.iloc[0].par['fwind']\n",
    "\n",
    "        if f == 'bathtub':\n",
    "            drainage = p.iloc[0].par['drainage']\n",
    "            par_str = f'c=%g d=%g w=%g' % (capacity, drainage, fwind)\n",
    "            X, cmap = bathtub_set(mydata, utils.bathtub_, capacity=capacity,\n",
    "                                  drainage=drainage, fwind=fwind)\n",
    "            mydata['soil_moisture'] = X[:, 0]\n",
    "        elif f == 'bathtub_geom':\n",
    "            drainage_factor = p.iloc[0].par['drainage_factor']\n",
    "            fwind = p.iloc[0].par['fwind']\n",
    "            par_str = f'c=%g d_f=%g w=%g' % (capacity, drainage_factor, fwind)\n",
    "            X, cmap = bathtub_set(mydata, utils.bathtub_geom_, capacity=capacity,\n",
    "                                  drainage_factor=drainage_factor, fwind=fwind)\n",
    "            mydata['soil_moisture'] = X[:, 0]\n",
    "        else:\n",
    "            print(\"Uh\")\n",
    "        sns.scatterplot(data=mydata,\n",
    "                        y='nrides', x='soil_moisture',\n",
    "                        marker='o',\n",
    "                        ax=ax[vi]).set_title(f'%s score=%.2f %s' % (name, score, par_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(data = df, y ='nrides', x='rain_mm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mydf = utils.get_ridelogs()\n",
    "\n",
    "today = date.today()\n",
    "epoch = today - timedelta(weeks=2)\n",
    "fig, ax = plt.subplots(2, 1, figsize=(8,8))\n",
    "\n",
    "sns.lineplot(data=mydf[['date','nrides_raw']].query(\"date >= @epoch\").set_index('date'), ci='sd', ax=ax[0])\n",
    "#plt.xticks(rotation=-45)\n",
    "\n",
    "sns.lineplot(data=mydf[['date','rides']].query(\"date >= @epoch\").set_index('date'), ci='sd', ax=ax[1])\n",
    "plt.xticks(rotation=-45)\n",
    "\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    data=by_dow.reset_index()\n",
    "    #sns.barplot(data=data, hue='segment_id', x='rides_dow', y='weekday', orient='h')\n",
    "    #data.plot.barh()\n",
    "    data = data.pivot_table(index='weekday', columns='segment_id', values='rides_dow').apply(lambda x: x*100/sum(x), axis=0)\n",
    "    data.T.plot(kind=\"bar\", stacked=True)\n",
    "    data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epoch = today - timedelta(days=1)\n",
    "df.query(\"date > @epoch\").sort_values('nrides_raw')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
