{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Model the usage of MTB trails as a function of weather conditions\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import spearmanr\n",
    "import utils\n",
    "import math\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gather data\n",
    "md = utils.get_segment_metadata()\n",
    "#md['closest_ims'] = md['closest_ims'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rl_ = utils.get_ridelogs()\n",
    "\n",
    "# Trim junk\n",
    "md = md[['id', 'name', 'closest_ims']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Tabulate ridelog data with date as index\n",
    "rl2 = pd.pivot_table(rl_, index='date', values='effort_count', columns='segment_id')\n",
    "rl2.set_index(pd.DatetimeIndex(rl2.index.values), inplace=True)\n",
    "\n",
    "# resample daily, interpolate missing values, and diff against the previous day\n",
    "daily = rl2.resample('1D').interpolate().diff()\n",
    "# negative values might come up if Strava removes rides\n",
    "daily.clip(lower=0, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize by day-of-week average\n",
    "all_segs = daily.columns\n",
    "d2 = daily.reset_index()\n",
    "d3 = d2.melt(id_vars = 'index', value_vars=all_segs)\n",
    "d4 = d3.rename(columns = {'index' : 'date', 'value' : 'rides'})\n",
    "all_rides = pd.DataFrame(d4.groupby('date')['rides'].sum()).reset_index()\n",
    "all_rides['segment_id'] = 'ALL'\n",
    "#all_rides['closest_ims'] = '000'\n",
    "\n",
    "d4 = d4.append(all_rides)\n",
    "\n",
    "d4['weekday'] = d4['date'].dt.weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_dow = d4.groupby(['segment_id', 'weekday']).mean().rename(columns={'rides' : 'rides_dow'})\n",
    "d5 = d4.merge(by_dow, how='left', left_on=['segment_id', 'weekday'], right_on=['segment_id', 'weekday'])\n",
    "# normalize (nrides = normalized rides)\n",
    "d5['nrides'] = d5['rides'] / d5['rides_dow']\n",
    "\n",
    "# negative values might come up if Strava removes rides\n",
    "# positive values which are too high are not useful for the analysis\n",
    "d5['nrides'].clip(lower=0, upper=1.5, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the closest IMS station\n",
    "d6 = d5.merge(md[['id', 'closest_ims', 'name']], how='right', left_on=['segment_id'], right_on=['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#d6['closest_ims'] = d6['closest_ims'].astype(int)\n",
    "#d6['closest_ims'].fillna('000')\n",
    "#d6['closest_ims'] = d6['closest_ims'].as_type(str)\n",
    "rain_days = utils.get_rain_days(d6)\n",
    "#d6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Add rain measurements\n",
    "data = d6.merge(rain_days, how='left', left_on=['closest_ims', 'date'], right_on=['closest_ims', 'date'])\n",
    "\n",
    "# cumulative measures of rainfall\n",
    "\n",
    "data.sort_values('date', inplace=True)\n",
    "data['rain_7d'] = data.groupby('segment_id')['rain_mm'].apply(lambda x : x.rolling(7).sum()).fillna(0)\n",
    "#data['soil_moisture'] = data.groupby('segment_id')['rain_mm'].apply(utils.bathtub)\n",
    "df_orig = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#data = data_orig.query(\"segment_id == '7774409'\").copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#data.groupby('segment_id').sum().sort_values('rides')\n",
    "#df_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def bathtub_set(data_, capacity, drainage):\n",
    "     return utils.bathtub_(data_['rain_mm'].values, capacity=capacity, drainage=drainage)\n",
    "\n",
    "def regress(X, y):\n",
    "    tofit = pd.DataFrame(data={'X' : X, 'y' : y}).dropna()\n",
    "    X = tofit.X.values\n",
    "    nrows = X.shape[0]\n",
    "    y = tofit.y.values\n",
    "    X = X.reshape(nrows, 1)\n",
    "    y = y.reshape(nrows, 1)\n",
    "    try:\n",
    "        reg = LinearRegression().fit(X, y)\n",
    "        return {'coef' : reg.coef_[0][0], 'intercept' : reg.intercept_[0], 'score' : reg.score(X, y)}\n",
    "    except ValueError:   # probably not enough data\n",
    "        return {'coef' : None, 'intercept' : None, 'score' : -1}\n",
    "\n",
    "def best_bathtub(data_):\n",
    "    mydata = data_.copy()\n",
    "    out = []\n",
    "\n",
    "    for c in range(0,80,4):\n",
    "        for d in range(0,25):\n",
    "            # TODO:\n",
    "            # 1. downsample the observations with no moisture and many rides\n",
    "            p = regress(bathtub_set(mydata, c, d), mydata['nrides'])\n",
    "            out.append([c, d, p['coef'], p['intercept'], p['score']])\n",
    "        \n",
    "    cdf = pd.DataFrame(out, columns=['capacity','drainage', 'coef', 'intercept', 'score'])\n",
    "    idxmax = cdf['score'].idxmax()\n",
    "    if(math.isnan(idxmax)):\n",
    "        idxmax = 0\n",
    "    return cdf.iloc[idxmax]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = df_orig.copy()\n",
    "out = []\n",
    "for seg in df['segment_id'].unique():\n",
    "    mydata = df.query(\"segment_id == @seg\")\n",
    "    res = best_bathtub(mydata).to_dict()\n",
    "    res['segment_id'] = seg\n",
    "    out.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "params = pd.DataFrame(out)\n",
    "# Compute the moisture value needed to reach nrides=1\n",
    "params['x1'] = -params['intercept']/params['coef']\n",
    "# Maximum days to reach this moisture value\n",
    "params['dfactor_lr'] = (params['capacity'] - params['x1'])/params['drainage']\n",
    "params['dfactor'] = params['capacity']/params['drainage']\n",
    "params = params.merge(md, how='left', left_on='segment_id', right_on='id')\n",
    "params[['capacity', 'drainage', 'score', 'segment_id']].to_csv('data/segments/params.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "sns.set_style('ticks')\n",
    "sns.scatterplot(data=params, x='capacity', y='drainage', size='score', hue='score', ax=ax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "names = df['segment_id'].unique()\n",
    "fig, ax = plt.subplots(figsize=(10,50), nrows=len(names), ncols=1)\n",
    "\n",
    "for vi in range(len(names)):\n",
    "    seg = names[vi]\n",
    "    mydata = df.query(\"segment_id == @seg\").copy()\n",
    "    p = params.query(\"id == @seg\")\n",
    "    capacity = p.iloc[0].capacity\n",
    "    drainage = p.iloc[0].drainage\n",
    "    score = p.iloc[0]['score']\n",
    "    name = mydata.iloc[0]['name']\n",
    "    mydata['soil_moisture'] = bathtub_set(mydata, capacity, drainage)\n",
    "    sns.scatterplot(data=mydata,\n",
    "                    y='nrides', x='soil_moisture',\n",
    "                    hue='segment_id', marker='o',\n",
    "                    ax=ax[vi]).set_title(f'%s c=%d d=%d score=%.2f' % (name, capacity, drainage, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg = '5230474' # 'ALL'\n",
    "mydata = df.query(\"segment_id == @seg\")\n",
    "#mydata\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data = mydata, y ='nrides', x='rain_mm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(data=mydata[['date','nrides']].set_index('date'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=by_dow.reset_index()\n",
    "#sns.barplot(data=data, hue='segment_id', x='rides_dow', y='weekday', orient='h')\n",
    "#data.plot.barh()\n",
    "data = data.pivot_table(index='weekday', columns='segment_id', values='rides_dow').apply(lambda x: x*100/sum(x), axis=0)\n",
    "data.T.plot(kind=\"bar\", stacked=True)\n",
    "data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
