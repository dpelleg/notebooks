{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Model the usage of MTB trails as a function of weather conditions\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import spearmanr\n",
    "import utils\n",
    "import math\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "import numpy as np\n",
    "from datetime import date, timedelta\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "# do we really need this? is it version-dependent?\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# gather data\n",
    "md = utils.get_segment_metadata()\n",
    "# ignore inactive segments\n",
    "md = md[md['active_modeling']]\n",
    "\n",
    "#md['closest_ims'] = md['closest_ims'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rl_ = utils.get_ridelogs()\n",
    "\n",
    "# Trim junk\n",
    "md = md[['id', 'name', 'closest_ims']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "d5 = rl_.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# add the closest IMS station\n",
    "d6 = d5.merge(md[['id', 'closest_ims', 'name']], how='right', left_on=['segment_id'], right_on=['id'])\n",
    "#md[['name','closest_ims']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "weather_days = utils.get_weather_days(d6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Add rain measurements\n",
    "data = d6.merge(weather_days, how='left', left_on=['closest_ims', 'date'], right_on=['closest_ims', 'date'])\n",
    "\n",
    "# cumulative measures of rainfall\n",
    "\n",
    "data.sort_values('date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# add lockdown value\n",
    "data['lockdown'] = 0\n",
    "data.loc[data['date'].between('2021-01-07', '2021-02-06'), 'lockdown'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data['rain_7d'] = data.fillna(0).groupby('segment_id')['rain_mm'].apply(lambda x : x.rolling(7).sum().clip(lower=0))\n",
    "#data['soil_moisture'] = data.groupby('segment_id')['rain_mm'].apply(utils.bathtub)\n",
    "df_orig = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "u_w = 0.1   # how much weight to give to the uniformity measure\n",
    "\n",
    "def bathtub_set(data_, soilmodel, include_rain=True, **kwargs):\n",
    "    # we get no information from days with dry soil - there's many of them and nothing to learn from\n",
    "    # filter out days with no rain in last 7 days\n",
    "    #print(data_.shape)\n",
    "    rows_included = data_['rain_7d'].fillna(-1).values > 0\n",
    "    data_ = data_.loc[rows_included]\n",
    "    #print(data_.shape)\n",
    "    soil = np.array(soilmodel(data_[['rain_mm', 'wind_ms']], **kwargs)).reshape(-1, 1)\n",
    "    if include_rain:\n",
    "        rain = (np.array(data_['rain_morning']) > 5).astype(int)    # indicator for: was there any rain on this particular morning?   \n",
    "    else:\n",
    "        rain = np.zeros_like(data_['rain_mm'])                 # fill with zeros\n",
    "    rain = rain.reshape(-1, 1)\n",
    "    temp = (np.array(data_['temp_morning']) > 12).astype(int)    # indicator for: was it a warm morning?\n",
    "    temp = temp.reshape(-1, 1)\n",
    "    lockdown = np.array(data_['lockdown']).reshape(-1, 1)\n",
    "    X = np.concatenate((soil, rain, lockdown, temp), axis=1)\n",
    "    y = data_['nrides']\n",
    "    cmap = ['soil', 'rain', 'lockdown', 'temp']\n",
    "    return (X, y, cmap)\n",
    "\n",
    "def uniformity(vv):\n",
    "    # measure how a univariate distribution is uniform, on a scale of 0 (one-hot) to 1 (perfectly uniform)\n",
    "    # from https://stats.stackexchange.com/questions/25827/how-does-one-measure-the-non-uniformity-of-a-distribution\n",
    "    d=3    # number of bins\n",
    "    hist, bin_edges = np.histogram(vv, bins=d, density=False)\n",
    "    hist = hist/np.sum(hist)\n",
    "    l2 = np.linalg.norm(hist)\n",
    "    u = (l2*np.sqrt(d)-1) / (np.sqrt(d)-1) \n",
    "    return 1-u\n",
    "\n",
    "def regress(X, y, sanity_checks=True):\n",
    "    # remove NaNs. We do this by stuffing everything into a dataframe first\n",
    "    dfXy = pd.DataFrame(X)\n",
    "    dfXy['y'] = y.values\n",
    "    dfXy.dropna(inplace=True)\n",
    "    # now unpack\n",
    "    Xy = np.array(dfXy.values)\n",
    "    X = Xy[:,:-1]\n",
    "    y = Xy[:, -1].reshape(-1, 1)\n",
    "\n",
    "    nrows = X.shape[0]\n",
    "    # skip if there's too little data\n",
    "    # skip if the moisture model didn't give us examples of dry soil (below 1)\n",
    "    # skip if the moisture model didn't give us examples of non-dry soil (above 1)\n",
    "    # skip if there isn't enough variation in the Y values\n",
    "    if (nrows <= 2) or (X[:, 0].min() > 1) or (X[:, 0].max() <= 1) or (y.ptp() < .25):\n",
    "        return {'coef' : None, 'intercept' : None, 'score' : -1}\n",
    "    # We typically get many many examples with X=0 (dry soil), down-weigh them to at most 1/3 of all data\n",
    "    Xsoil = X[:, 0].reshape(-1)\n",
    "    u_val = uniformity(Xsoil)\n",
    "    weights = np.ones(Xsoil.shape)\n",
    "    nzeros = np.count_nonzero(Xsoil == 0)\n",
    "    if nzeros > 0:\n",
    "        norm_factor = min(1.0, (1/3.0)*(1.0*nrows/nzeros))\n",
    "        if False and random.random() < 0.001:\n",
    "            print(\"%d rows %d nzeros factor %f\" % (nrows, nzeros, norm_factor))\n",
    "        # we collapse all the zero points to have a total weight of one\n",
    "        weights[Xsoil == 0] = norm_factor\n",
    "    try:\n",
    "        reg = Ridge(alpha=1E-6, normalize=True).fit(X, y, sample_weight = weights)\n",
    "        #reg = LinearRegression(normalize=True).fit(X, y, sample_weight = weights)\n",
    "        coef = reg.coef_[0]\n",
    "        score = reg.score(X, y, sample_weight = weights)\n",
    "        # apply some sanity checks\n",
    "        if sanity_checks:\n",
    "            # we need more soil moisture = less rides, not the opposite\n",
    "            if coef[0] > 0:\n",
    "                score = -1\n",
    "            # we need more rain today = less rides, not the opposite\n",
    "            if coef[1] > 0:\n",
    "                score = -1\n",
    "            # we need more lockdown today = less rides, not the opposite\n",
    "            if coef[2] > 0:\n",
    "                score = -1\n",
    "        return {'coef' : reg.coef_[0], 'intercept' : reg.intercept_[0], 'score' : score, 'uniformity' : u_val}\n",
    "    except ValueError:   # probably not enough data\n",
    "        return {'coef' : None, 'intercept' : None, 'score' : -1, 'uniformity' : -1}\n",
    "\n",
    "def best_bathtub(data_):\n",
    "    mydata = data_.copy()\n",
    "    out = []\n",
    "\n",
    "    # Try the geometric model\n",
    "    clist = list(np.arange(4, 80, 4))\n",
    "    #clist = list(np.arange(4, 50, 8))\n",
    "\n",
    "    dlist = list(np.arange(0.5, 0.65, 0.05))\n",
    "    dlist.extend(np.arange(0.65, 0.8, 0.05))\n",
    "    dlist.extend(np.arange(0.8, 1, 0.05))\n",
    "\n",
    "    wlist = list(np.arange(0, 3, 0.25))\n",
    "    #wlist = [0, 1]\n",
    "    #wlist = []\n",
    "\n",
    "    for c in clist:\n",
    "        for d in dlist:\n",
    "            for w in wlist:\n",
    "                X, y, cmap = bathtub_set(mydata, utils.bathtub_geom_, capacity=c, drainage_factor=d, fwind=w)\n",
    "                p = regress(X, y)\n",
    "                if p['score'] > -1:\n",
    "                    outdict = {'f': 'bathtub_geom', 'capacity': c, 'drainage_factor' : d, 'fwind' : w,\n",
    "                               'intercept' : p['intercept']}\n",
    "                    for ci in range(len(cmap)):\n",
    "                        outdict['c_' + cmap[ci]] = p['coef'][ci]\n",
    "                    out.append([p['score'], p['uniformity'], outdict])\n",
    "    \n",
    "    #Try the basic model\n",
    "    clist = list(np.arange(1, 10, 0.5))\n",
    "    clist.extend(range(10,80,4))\n",
    "    #clist = range(10, 30, 5)\n",
    "    \n",
    "    dlist = list(np.arange(5, 10, 0.5))\n",
    "    dlist.extend(range(10,25))\n",
    "    \n",
    "    wlist = list(np.arange(0, 3, 0.25))\n",
    "    #wlist = []\n",
    "    \n",
    "    for c in clist:\n",
    "        for d in dlist:\n",
    "            for w in wlist:\n",
    "                # we want to ensure some margin between capacity and drainage\n",
    "                if c > d + 2:\n",
    "                    X, y, cmap = bathtub_set(mydata, utils.bathtub_, capacity=c, drainage=d, fwind=w)\n",
    "                    p = regress(X, y)\n",
    "                    if p['score'] > -1:\n",
    "                        outdict = {'f': 'bathtub', 'capacity': c, 'drainage' : d, 'fwind' : w,\n",
    "                                             'intercept' : p['intercept']}\n",
    "                        for ci in range(len(cmap)):\n",
    "                            outdict['c_' + cmap[ci]] = p['coef'][ci]\n",
    "                        out.append([p['score'], p['uniformity'], outdict])\n",
    "\n",
    "    #Try the day-counter model\n",
    "    tlist = [1, 5, 7.5, 10, 15]\n",
    "    \n",
    "    dlist = range(1, 7)\n",
    "    \n",
    "    wlist = list(np.arange(0, 2, 0.2))\n",
    "    #wlist = []\n",
    "    \n",
    "    for t in tlist:\n",
    "        for d in dlist:\n",
    "            for w in wlist:\n",
    "                    X, y, cmap = bathtub_set(mydata, utils.daycounter_, include_rain=False, cday=d, rain_thresh=t, fwind=w)\n",
    "                    p = regress(X, y)\n",
    "                    if p['score'] > -1:\n",
    "                        outdict = {'f': 'daycounter', 'cday' : d, 'rain_thresh': t, 'fwind' : w,\n",
    "                                             'intercept' : p['intercept']}\n",
    "                        for ci in range(len(cmap)):\n",
    "                            outdict['c_' + cmap[ci]] = p['coef'][ci]\n",
    "                        out.append([p['score'], p['uniformity'], outdict])\n",
    "\n",
    "                        \n",
    "    if(len(out) > 0):\n",
    "        cdf = pd.DataFrame(out, columns=['score', 'uniformity', 'par'])\n",
    "        cdf['cscore'] = (1.0-u_w)*cdf['score'] + u_w*cdf['uniformity']\n",
    "        idxmax = cdf['cscore'].idxmax()\n",
    "        if(math.isnan(idxmax)):\n",
    "            idxmax = 0\n",
    "        return cdf.iloc[idxmax]\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = df_orig.copy()\n",
    "out = []\n",
    "d = {}\n",
    "seglist = df['segment_id'].unique()\n",
    "#seglist = ['4136318']\n",
    "for seg in seglist:\n",
    "    print(seg, end=\"...\")\n",
    "    mydata = df.query(\"segment_id == @seg\")\n",
    "    res = best_bathtub(mydata)\n",
    "    if res is not None:\n",
    "        res = res.to_dict()\n",
    "        res['segment_id'] = seg\n",
    "        out.append(res)\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = pd.DataFrame(out)\n",
    "# Compute the days to dry\n",
    "params['dtd'] = None\n",
    "\n",
    "exploded = pd.DataFrame.from_records(params['par'])\n",
    "params = pd.concat([params, exploded], axis='columns')\n",
    "\n",
    "# check we have all needed columns\n",
    "for c in ['drainage', 'drainage_factor', 'rain_thresh', 'capacity', 'cday']:\n",
    "    if c not in params.columns:\n",
    "        params[c] = None\n",
    "\n",
    "\n",
    "# We compute the moisture value which yields 0.9 of the intercept (soil is 90% dry)\n",
    "params['y90'] = 0.9*exploded['intercept']\n",
    "params['x90'] = (params['y90'] - exploded['intercept'])/exploded['c_soil']\n",
    "\n",
    "# compute for the additive model\n",
    "rows = (params['f'] == 'bathtub')\n",
    "params.loc[rows, 'dtd'] = (params['capacity'] - params['x90'])/params['drainage']\n",
    "\n",
    "# compute for the geometric model\n",
    "rows = (params['f'] == 'bathtub_geom')\n",
    "# how many times to multiply by the factor until we reach a value of x90?\n",
    "params.loc[rows, 'dtd'] = params[rows].apply(lambda r: (math.log(r['y90']) -math.log(r['capacity']))/math.log(r['drainage_factor']), axis=1)\n",
    "\n",
    "# compute for the daycounter model\n",
    "rows = (params['f'] == 'daycounter')\n",
    "params.loc[rows, 'dtd'] = params.loc[rows, 'cday']\n",
    "\n",
    "params = params.merge(md, how='left', left_on='segment_id', right_on='id').drop(columns='id')\n",
    "params[['segment_id', 'score', 'par']].to_csv('data/segments/params.csv', float_format='%.3g', index=False)\n",
    "\n",
    "params[['name', 'dtd', 'score', 'uniformity', 'capacity', 'drainage', 'drainage_factor', 'cday', 'rain_thresh', 'fwind', 'c_lockdown', 'c_rain', 'c_soil', 'c_temp']].sort_values('score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3, 1, figsize=(8,8))\n",
    "sns.set_style('ticks')\n",
    "\n",
    "exploded = pd.DataFrame.from_records(params['par'])\n",
    "exploded['score'] = params['score']\n",
    "\n",
    "# plot for the additive model\n",
    "rows = (exploded['f'] == 'bathtub')\n",
    "if rows.sum() > 0:\n",
    "    sns.scatterplot(data=exploded[rows], x='capacity', y='drainage', size='score', hue='fwind', ax=ax[0])\n",
    "    ax[0].legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "    \n",
    "# plot for the geometric model\n",
    "rows = (exploded['f'] == 'bathtub_geom')\n",
    "if rows.sum() > 0:\n",
    "    sns.scatterplot(data=exploded[rows], x='capacity', y='drainage_factor', size='score', hue='fwind', ax=ax[1])\n",
    "    ax[1].legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "    \n",
    "# plot for the daycounter model\n",
    "rows = (exploded['f'] == 'daycounter')\n",
    "if rows.sum() > 0:\n",
    "    sns.scatterplot(data=exploded[rows], x='cday', y='rain_thresh', size='score', hue='fwind', ax=ax[2])\n",
    "    ax[2].legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "\n",
    "fig.tight_layout(pad=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "names = df['segment_id'].unique()\n",
    "fig, ax = plt.subplots(figsize=(10,50), nrows=len(names), ncols=1)\n",
    "\n",
    "for vi in range(len(names)):\n",
    "    seg = names[vi]\n",
    "    mydata = df.query(\"segment_id == @seg\").copy()\n",
    "    p = params.query(\"segment_id == @seg\")\n",
    "    if len(p) > 0:\n",
    "        f = p.iloc[0].par['f']\n",
    "        name = mydata.iloc[0]['name'][::-1]\n",
    "        score = p.iloc[0]['score']\n",
    "\n",
    "        fwind = p.iloc[0].par['fwind']\n",
    "\n",
    "        if f == 'bathtub':\n",
    "            capacity = p.iloc[0].par['capacity']\n",
    "            drainage = p.iloc[0].par['drainage']\n",
    "            par_str = f'c=%g d=%g w=%g' % (capacity, drainage, fwind)\n",
    "            X, y, cmap = bathtub_set(mydata, utils.bathtub_, capacity=capacity,\n",
    "                                     drainage=drainage, fwind=fwind)\n",
    "        elif f == 'bathtub_geom':\n",
    "            capacity = p.iloc[0].par['capacity']\n",
    "            drainage_factor = p.iloc[0].par['drainage_factor']\n",
    "            fwind = p.iloc[0].par['fwind']\n",
    "            par_str = f'c=%g d_f=%g w=%g' % (capacity, drainage_factor, fwind)\n",
    "            X, y, cmap = bathtub_set(mydata, utils.bathtub_geom_, capacity=capacity,\n",
    "                                     drainage_factor=drainage_factor, fwind=fwind)\n",
    "        elif f == 'daycounter':\n",
    "            cday = p.iloc[0].par['cday']\n",
    "            rain_thresh = p.iloc[0].par['rain_thresh']\n",
    "            fwind = p.iloc[0].par['fwind']\n",
    "            par_str = f'cday=%g r_t=%g w=%g' % (cday, rain_thresh, fwind)\n",
    "            X, y, cmap = bathtub_set(mydata, utils.daycounter_, cday=cday,\n",
    "                                     rain_thresh=rain_thresh, fwind=fwind)\n",
    "\n",
    "        else:\n",
    "            print(\"Uh\")\n",
    "        plot_data = pd.DataFrame(data = {'soil_moisture' : X[:, 0], 'nrides' : y})\n",
    "        sns.scatterplot(data=plot_data,\n",
    "                        y='nrides', x='soil_moisture',\n",
    "                        marker='o',\n",
    "                        ax=ax[vi]).set_title(f'%s score=%.2f %s' % (name, score, par_str))\n",
    "\n",
    "fig.tight_layout(pad=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    data=by_dow.reset_index()\n",
    "    #sns.barplot(data=data, hue='segment_id', x='rides_dow', y='weekday', orient='h')\n",
    "    #data.plot.barh()\n",
    "    data = data.pivot_table(index='weekday', columns='segment_id', values='rides_dow').apply(lambda x: x*100/sum(x), axis=0)\n",
    "    data.T.plot(kind=\"bar\", stacked=True)\n",
    "    data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
