{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Model the usage of MTB trails as a function of weather conditions\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import spearmanr\n",
    "import utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# gather data\n",
    "md = utils.get_segment_metadata()\n",
    "rl_ = utils.get_ridelogs()\n",
    "\n",
    "# Trip junk\n",
    "md = md[['id', 'name', 'closest_ims']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Tabulate ridelog data with date as index\n",
    "rl2 = pd.pivot_table(rl_, index='date', values='effort_count', columns='segment_id')\n",
    "rl2.set_index(pd.DatetimeIndex(rl2.index.values), inplace=True)\n",
    "\n",
    "# resample daily, interpolate missing values, and diff against the previous day\n",
    "daily = rl2.resample('1D').interpolate().fillna(method='bfill').diff()\n",
    "#todo: clip value to non-negative\n",
    "daily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize by day-of-week average\n",
    "all_segs = daily.columns\n",
    "d2 = daily.reset_index()\n",
    "d3 = d2.melt(id_vars = 'index', value_vars=all_segs)\n",
    "d4 = d3.rename(columns = {'index' : 'date', 'value' : 'rides'})\n",
    "d4['weekday'] = d4['date'].dt.weekday\n",
    "\n",
    "by_dow = d4.groupby(['segment_id', 'weekday']).mean().rename(columns={'rides' : 'rides_dow'})\n",
    "d5 = d4.merge(by_dow, how='left', left_on=['segment_id', 'weekday'], right_on=['segment_id', 'weekday'])\n",
    "# normalize (nrids = normalized rides)\n",
    "d5['nrides'] = d5['rides'] / d5['rides_dow']\n",
    "# negative values might come up if Strava removes rides\n",
    "# positive values which are too high are not useful for the analysis\n",
    "d5['nrides'].clip(lower=0, upper=2, inplace=True)\n",
    "d5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(daily.idxmax())\n",
    "daily.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# add the closest IMS station\n",
    "d6 = d5.merge(md[['id', 'closest_ims', 'name']], how='left', left_on=['segment_id'], right_on=['id'])\n",
    "\n",
    "rain_days = utils.get_rain_days(d6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Add rain measurements\n",
    "data = d6.merge(rain_days, how='left', left_on=['closest_ims', 'date'], right_on=['closest_ims', 'date'])\n",
    "\n",
    "# cumulative measures of rainfall\n",
    "\n",
    "data.sort_values('date', inplace=True)\n",
    "data['rain_7d'] = data.groupby('segment_id')['rain_mm'].apply(lambda x : x.rolling(7).sum()).fillna(0)\n",
    "data['soil_moisture'] = data.groupby('segment_id')['rain_mm'].apply(utils.bathtub)\n",
    "df_orig = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#data = data_orig.query(\"segment_id == '7774409'\").copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#data.groupby('segment_id').sum().sort_values('rides')\n",
    "#df_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def bathtub_set(data_, capacity, drainage):\n",
    "     return utils.bathtub_(data_['rain_mm'].values, capacity=capacity, drainage=drainage)\n",
    "\n",
    "def best_bathtub(data_):\n",
    "    mydata = data_.copy()\n",
    "    out = []\n",
    "\n",
    "    for c in range(0,80,4):\n",
    "        for d in range(0,25):\n",
    "            # TODO:\n",
    "            # 1. downsample the observations with no moisture and many rides\n",
    "            # 2. normalize the ride counts per day of week\n",
    "            corr, _ = spearmanr(mydata['nrides'].values, bathtub_set(mydata, c, d), nan_policy='omit')\n",
    "            out.append([c, d, corr])\n",
    "        \n",
    "    cdf = pd.DataFrame(out, columns=['capacity','drainage', 'corr'])\n",
    "    cdf['abscorr'] = cdf['corr'].transform('abs')\n",
    "    return cdf.iloc[cdf['abscorr'].idxmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = df_orig.copy()\n",
    "out = []\n",
    "for seg in df['segment_id'].unique():\n",
    "    mydata = df.query(\"segment_id == @seg\")\n",
    "    res = best_bathtub(mydata).to_dict()\n",
    "    res['segment_id'] = seg\n",
    "    out.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "params = pd.DataFrame(out)\n",
    "params['dfactor'] = params['capacity'] / params['drainage']\n",
    "params = params.merge(md, how='left', left_on='segment_id', right_on='id')\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "sns.set_style('ticks')\n",
    "sns.scatterplot(data=params, x='capacity', y='drainage', size='abscorr', hue='abscorr', ax=ax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "names = df['segment_id'].unique()\n",
    "fig, ax = plt.subplots(figsize=(10,60), nrows=len(names), ncols=1)\n",
    "\n",
    "for vi in range(len(names)):\n",
    "    seg = names[vi]\n",
    "    mydata = df.query(\"segment_id == @seg\").copy()\n",
    "    p = params.query(\"id == @seg\")\n",
    "    capactiy = p.iloc[0].capacity\n",
    "    drainage = p.iloc[0].drainage\n",
    "    name = mydata.iloc[0]['name']\n",
    "    mydata['soil_moisture'] = bathtub_set(mydata, capacity, drainage)\n",
    "    sns.scatterplot(data=mydata,\n",
    "                    y='nrides', x='soil_moisture',\n",
    "                    hue='segment_id', marker='o',\n",
    "                    ax=ax[vi]).set_title(f'%s c=%d d=%d' % (name, capacity, drainage))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
